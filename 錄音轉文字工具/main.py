import os
import sys
import time
import argparse
import warnings
from faster_whisper import WhisperModel
from opencc import OpenCC
from tqdm import tqdm
from colorama import init, Fore, Style

# Initialize colorama
init(autoreset=True)

# Suppress warnings
warnings.filterwarnings("ignore")

def trans_to_traditional(text):
    cc = OpenCC('s2twp') # Simplified to Traditional (Taiwan)
    return cc.convert(text)

def format_time(seconds):
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return f"{int(h):02d}:{int(m):02d}:{int(s):02d}"

def process_file(model, file_path, output_dir):
    filename = os.path.basename(file_path)
    name, _ = os.path.splitext(filename)
    output_path = os.path.join(output_dir, f"{name}.txt")
    
    print(f"\n{Fore.CYAN}ğŸ§ æ­£åœ¨è™•ç†æª”æ¡ˆ: {filename}{Style.RESET_ALL}")
    
    start_time = time.time()
    
    try:
        # Transcribe
        # beam_size=5 is standard for accuracy
        segments, info = model.transcribe(file_path, beam_size=5, vad_filter=True)
        
        print(f"{Fore.GREEN}â„¹ï¸  åµæ¸¬èªè¨€: {info.language.upper()}  (æ©Ÿç‡: {info.language_probability:.0%}){Style.RESET_ALL}")
        print(f"{Fore.GREEN}â„¹ï¸  éŸ³è¨Šé•·åº¦: {format_time(info.duration)}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}â³ è½‰éŒ„ä¸­...{Style.RESET_ALL}")
        
        # Collect segments with progress bar
        # Since segments is a generator, we can't know exact total segments easily without creating them,
        # but faster-whisper yields them as they are processed.
        # We can use the duration to estimate progress if we wanted, but simple tqdm on generator is tricky.
        # We will manually print progress.
        
        results = []
        pbar = tqdm(total=round(info.duration, 2), unit='sec', bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]")
        
        for segment in segments:
            # Convert text to Traditional Chinese
            text = segment.text
            # If language is Chinese, ensure Traditional. If English, keep as is (or translate?).
            # User requirement: "Convert received Chinese/English recordings to Traditional Chinese".
            # If Audio is English -> Text is English. User might want English->TradChinese?
            # Usually "Speech to Text" means transcription. 
            # If the user wants TRANSLATION (En audio -> Zh text), that's a different task.
            # Assuming Transcription first. 
            # If Audio is Chinese -> Output Simplified (usually) -> Convert to Traditional.
            # If Audio is English -> Output English.
            
            # Let's apply OpenCC to everything. It won't hurt English, but will fix Simplified Chinese.
            processed_text = trans_to_traditional(text)
            
            line = f"[{format_time(segment.start)} -> {format_time(segment.end)}] {processed_text}"
            results.append(line)
            
            pbar.update(segment.end - pbar.n)
            
        pbar.close()
        
        # Save to file
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"æª”å: {filename}\n")
            f.write(f"èªè¨€: {info.language}\n")
            f.write(f"é•·åº¦: {format_time(info.duration)}\n")
            f.write("-" * 30 + "\n\n")
            f.write("\n".join(results))
            
        print(f"{Fore.GREEN}âœ… å®Œæˆï¼å·²å„²å­˜è‡³: {output_path}{Style.RESET_ALL}")
        
    except Exception as e:
        print(f"{Fore.RED}âŒ è™•ç†å¤±æ•—: {e}{Style.RESET_ALL}")

def main():
    parser = argparse.ArgumentParser(description="é›¢ç·šéŒ„éŸ³è½‰æ–‡å­—å·¥å…· (æ”¯æ´ä¸­/è‹± -> ç¹é«”ä¸­æ–‡)")
    parser.add_argument("input", nargs='+', help="è¼¸å…¥çš„éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ (æ”¯æ´ mp3, wav, m4a, mp4 ç­‰)")
    parser.add_argument("--model", default="medium", choices=["tiny", "base", "small", "medium", "large-v3"], help="æ¨¡å‹å¤§å° (é è¨­: medium)")
    parser.add_argument("--output", "-o", default="output", help="è¼¸å‡ºç›®éŒ„ (é è¨­: output)")
    parser.add_argument("--compute_type", default="int8", help="é‹ç®—ç²¾åº¦ (default: int8, Mac å¯è©¦ float16)")
    
    args = parser.parse_args()
    
    # Check output dir
    if not os.path.exists(args.output):
        os.makedirs(args.output)
        
    print(f"{Fore.MAGENTA}ğŸš€ åˆå§‹åŒ–æ¨¡å‹: {args.model} ... (é¦–æ¬¡åŸ·è¡Œéœ€ä¸‹è¼‰æ¨¡å‹){Style.RESET_ALL}")
    try:
        # device='cpu' or 'cuda'. On Mac M1/M2, faster-whisper runs on CPU with CTranslate2 optimization usually efficiently.
        # coreml is another option but complex setup.
        # Just use 'cpu' for broad compatibility or 'auto'.
        model = WhisperModel(args.model, device="auto", compute_type=args.compute_type)
    except Exception as e:
        print(f"{Fore.RED}æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}{Style.RESET_ALL}")
        return

    for file_path in args.input:
        if os.path.isfile(file_path):
            process_file(model, file_path, args.output)
        else:
            print(f"{Fore.RED}æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}{Style.RESET_ALL}")

    print(f"\n{Fore.MAGENTA}ğŸ‰ å…¨éƒ¨å·¥ä½œå®Œæˆï¼{Style.RESET_ALL}")

if __name__ == "__main__":
    main()
